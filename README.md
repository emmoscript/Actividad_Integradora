# ğŸš€ Actividad PrÃ¡ctica Integradora: Big-Data Serverless

## ğŸ“‹ DescripciÃ³n del Proyecto

**Desarrollo de una AplicaciÃ³n HÃ­brida de Procesamiento Big-Data en Entorno Serverless**

Este proyecto implementa un sistema completo de procesamiento Big-Data que combina **GPU acceleration**, **Apache Spark**, **modelo de actores** y **arquitectura serverless** en AWS. El sistema demuestra competencias avanzadas en programaciÃ³n paralela y distribuida.

### ğŸ¯ Objetivos

- **GPU Preprocessing**: Microservicio serverless con CUDA/OpenMP para normalizaciÃ³n de datos
- **Spark Processing**: Jobs con RDD y DataFrame pipelines comparando rendimiento
- **Actor Model**: OrquestaciÃ³n con Akka/Thespian para coordinaciÃ³n distribuida
- **Serverless Architecture**: Escalabilidad automÃ¡tica y procesamiento bajo demanda
- **AnÃ¡lisis de Rendimiento**: Benchmarks completos y mÃ©tricas de performance

---

## ğŸ—ï¸ Arquitectura del Sistema

### Diagrama de Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Gateway   â”‚â”€â”€â”€â–¶â”‚  Lambda Router  â”‚â”€â”€â”€â–¶â”‚  Actor System   â”‚
â”‚   (HTTP API)    â”‚    â”‚   (Orchestrator)â”‚    â”‚   (Thespian)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GPU Processing â”‚â—€â”€â”€â”€â”‚  Lambda GPU     â”‚â—€â”€â”€â”€â”‚  Validation     â”‚
â”‚  (CUDA/OpenMP)  â”‚    â”‚  Microservice   â”‚    â”‚  Actor          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Spark Cluster  â”‚â—€â”€â”€â”€â”‚  Lambda Spark   â”‚â—€â”€â”€â”€â”‚  Job Manager    â”‚
â”‚  (RDD/DataFrame)â”‚    â”‚  Launcher       â”‚    â”‚  Actor          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  S3 Storage     â”‚â—€â”€â”€â”€â”‚  Result         â”‚â—€â”€â”€â”€â”‚  Analysis       â”‚
â”‚  (Results)      â”‚    â”‚  Collector      â”‚    â”‚  Actor          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Principales

#### 1. **API Gateway**
- **Endpoint**: `https://6p16xjty3i.execute-api.us-east-1.amazonaws.com/dev/process`
- **MÃ©todo**: POST
- **FunciÃ³n**: Punto de entrada HTTP para procesamiento de datos

#### 2. **Lambda Orchestrator**
- **FunciÃ³n**: CoordinaciÃ³n principal del workflow
- **Responsabilidades**:
  - ValidaciÃ³n de entrada
  - InvocaciÃ³n de GPU y Spark Lambdas
  - RecolecciÃ³n y consolidaciÃ³n de resultados
  - Manejo de errores y retries

#### 3. **GPU Processing Lambda**
- **TecnologÃ­a**: SimulaciÃ³n de CUDA con CuPy/NumPy
- **Proceso**: NormalizaciÃ³n de datos numÃ©ricos
- **Algoritmo**: Z-score normalization
- **Fallback**: CPU processing si GPU no disponible

#### 4. **Spark Processing Lambda**
- **Pipelines**: RDD y DataFrame
- **Operaciones**: Transformaciones y agregaciones
- **ComparaciÃ³n**: Speedup calculation
- **Storage**: Resultados en S3

#### 5. **Actor System (Thespian)**
- **Validation Actor**: ValidaciÃ³n de datos de entrada
- **Job Manager Actor**: CoordinaciÃ³n de jobs
- **Analysis Actor**: AnÃ¡lisis de resultados
- **Response Actor**: PreparaciÃ³n de respuesta final

#### 6. **S3 Storage**
- **Bucket**: `bigdata-processing-results-emil-3085`
- **Estructura**:
  - `gpu_results/{job_id}/normalized_data.json`
  - `spark_results/{job_id}/processing_results.json`
  - `final_results/{job_id}/summary.json`

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### AWS Services
- **Lambda**: Procesamiento serverless
- **API Gateway**: Endpoint HTTP RESTful
- **S3**: Almacenamiento persistente
- **CloudWatch**: Monitoreo y logs
- **IAM**: Seguridad y permisos

### Python Libraries
- **boto3**: AWS SDK para Python
- **thespian**: Sistema de actores (equivalente a Akka)
- **numpy**: Procesamiento numÃ©rico
- **cupy**: GPU acceleration (simulado)
- **requests**: HTTP client
- **matplotlib**: Visualizaciones
- **pandas**: ManipulaciÃ³n de datos

### Infrastructure as Code
- **Terraform**: Despliegue de infraestructura AWS
- **PowerShell**: Scripts de automatizaciÃ³n

---

## ğŸ“Š AnÃ¡lisis de Rendimiento

### ComparaciÃ³n RDD vs DataFrame

| Dataset Size | RDD Time (s) | DataFrame Time (s) | Speedup | RDD Throughput | DataFrame Throughput |
|--------------|--------------|-------------------|---------|----------------|---------------------|
| 1,000        | 0.136        | 0.129             | 1.05x   | 7,373          | 7,737               |
| 5,000        | 0.157        | 0.152             | 1.04x   | 31,770         | 32,964              |
| 10,000       | 0.221        | 0.317             | 0.70x   | 45,210         | 31,569              |
| 25,000       | 0.388        | 0.307             | 1.26x   | 64,430         | 81,301              |

### Insights de Rendimiento

#### **GPU vs CPU Processing**
- **GPU Simulation**: NormalizaciÃ³n con CuPy (simulado)
- **CPU Fallback**: Procesamiento con NumPy
- **Speedup**: 1.0x (simulado para demostraciÃ³n)
- **Ventajas**: ParalelizaciÃ³n masiva, optimizaciÃ³n de memoria

#### **RDD vs DataFrame Performance**
- **Small Datasets (1K-5K)**: DataFrame ligeramente mejor (1.04-1.05x)
- **Medium Datasets (10K)**: RDD mejor performance (1.43x speedup)
- **Large Datasets (25K)**: DataFrame significativamente mejor (1.26x)
- **Throughput**: DataFrame escala mejor para datasets grandes

#### **Serverless Performance**
- **Cold Start**: ~200ms para Lambda functions
- **Processing Time**: < 1 segundo para datasets hasta 25K registros
- **Scalability**: Auto-scaling automÃ¡tico
- **Cost Efficiency**: Pay-per-use model

### AnÃ¡lisis de Costos

| Dataset Size | Lambda Cost | S3 Cost | EMR Cost | Total Cost | Cost per Record |
|--------------|-------------|---------|----------|------------|-----------------|
| 1,000        | $0.001      | $0.0001 | $0.150   | $0.151     | $0.000151       |
| 5,000        | $0.001      | $0.0001 | $0.150   | $0.151     | $0.000030       |
| 10,000       | $0.001      | $0.0001 | $0.150   | $0.151     | $0.000015       |
| 50,000       | $0.001      | $0.0001 | $0.150   | $0.151     | $0.000003       |

**EconomÃ­as de Escala**: Costo por registro disminuye significativamente con el tamaÃ±o del dataset.

---

## ğŸ“ Estructura del Proyecto

```
PrÃ¡cticaIntegradora/
â”œâ”€â”€ README.md                           # DocumentaciÃ³n principal
â”œâ”€â”€ requirements.txt                    # Dependencias Python
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ actors/                         # Sistema de actores Thespian
â”‚   â”‚   â”œâ”€â”€ base_actor.py              # Actor base con retry logic
â”‚   â”‚   â”œâ”€â”€ validation_actor.py        # ValidaciÃ³n de entrada
â”‚   â”‚   â”œâ”€â”€ job_manager_actor.py       # GestiÃ³n de jobs
â”‚   â”‚   â”œâ”€â”€ analysis_actor.py          # AnÃ¡lisis de resultados
â”‚   â”‚   â””â”€â”€ response_actor.py          # PreparaciÃ³n de respuesta
â”‚   â”œâ”€â”€ lambda_functions/              # Funciones AWS Lambda
â”‚   â”‚   â”œâ”€â”€ orchestrator/              # Orquestador principal
â”‚   â”‚   â”œâ”€â”€ gpu_processing/            # Procesamiento GPU
â”‚   â”‚   â””â”€â”€ spark_launcher/            # Lanzador de Spark
â”‚   â””â”€â”€ spark_jobs/                    # Scripts de Spark
â”‚       â”œâ”€â”€ rdd_pipeline.py            # Pipeline RDD
â”‚       â””â”€â”€ dataframe_pipeline.py      # Pipeline DataFrame
â”œâ”€â”€ deployment/                         # Scripts de despliegue
â”‚   â”œâ”€â”€ terraform/                     # Infrastructure as Code
â”‚   â””â”€â”€ scripts/                       # Scripts de automatizaciÃ³n
â”œâ”€â”€ examples/                          # Ejemplos y demos
â”‚   â”œâ”€â”€ demo_usage.py                  # Demo completo
â”‚   â””â”€â”€ performance_analysis.png       # GrÃ¡ficos de rendimiento
â”œâ”€â”€ tests/                             # Tests unitarios e integraciÃ³n
â””â”€â”€ scripts/                           # Scripts de utilidad
    â”œâ”€â”€ test_api.py                    # Prueba simple de API
    â”œâ”€â”€ quick_test.py                  # Prueba rÃ¡pida
    â”œâ”€â”€ simple_logs.py                 # VerificaciÃ³n de logs
    â””â”€â”€ generate_report.py             # Generador de reportes
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- **Python 3.9+**
- **AWS CLI** configurado
- **Terraform** instalado
- **PowerShell** (Windows)

### InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone <repository-url>
cd PrÃ¡cticaIntegradora
```

2. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

3. **Configurar AWS**
```bash
aws configure
```

### Despliegue

1. **Ejecutar script de despliegue**
```powershell
cd deployment/scripts
.\deploy.ps1
```

2. **Verificar despliegue**
```bash
python quick_test.py
```

---

## ğŸ“– Uso del Sistema

### 1. Prueba RÃ¡pida

```bash
python quick_test.py
```

**Salida esperada:**
```
ğŸ§ª Quick API Test
========================================
URL: https://6p16xjty3i.execute-api.us-east-1.amazonaws.com/dev/process
ğŸ“¡ Sending request...
ğŸ“Š Status: 200
â±ï¸  Time: 0.58s
âœ… Success!
   Job ID: 17564205-f6cf-4bac-a963-ede95160678f
   Status: completed
   Total Time: 0.207s
   Data Processed: 5
ğŸ‰ API is working correctly!
```

### 2. Demo Completo

```bash
cd examples
python demo_usage.py
```

**Incluye:**
- Test de funcionalidad bÃ¡sica
- ComparaciÃ³n de pipelines RDD vs DataFrame
- Benchmark de escalabilidad
- AnÃ¡lisis de calidad de datos
- AnÃ¡lisis de costos
- GeneraciÃ³n de visualizaciones

### 3. VerificaciÃ³n de Logs

```bash
python simple_logs.py
```

### 4. GeneraciÃ³n de Reportes

```bash
python generate_report.py
```

---

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Variables de Entorno

```bash
export AWS_REGION=us-east-1
export S3_BUCKET=bigdata-processing-results-emil-3085
export API_GATEWAY_URL=https://6p16xjty3i.execute-api.us-east-1.amazonaws.com/dev/process
```

### ConfiguraciÃ³n Lambda

- **Memory**: 1024 MB
- **Timeout**: 900 segundos
- **Runtime**: Python 3.9
- **Environment Variables**: Configuradas automÃ¡ticamente

### Monitoreo

- **CloudWatch Logs**: Disponibles para todas las funciones
- **MÃ©tricas**: Latencia, errores, invocaciones
- **Alertas**: Configurables para errores y latencia alta

---

## ğŸ§ª Testing

### Tests Unitarios

```bash
python -m pytest tests/ -v
```

### Tests de IntegraciÃ³n

```bash
python tests/test_integration.py
```

### Tests de Performance

```bash
python examples/demo_usage.py
```

---

## ğŸ“ˆ MÃ©tricas y Monitoreo

### MÃ©tricas Clave

- **Throughput**: Registros procesados por segundo
- **Latencia**: Tiempo de respuesta total
- **Speedup**: ComparaciÃ³n RDD vs DataFrame
- **Cost Efficiency**: Costo por registro procesado
- **Error Rate**: Porcentaje de errores

### Dashboards Recomendados

- **CloudWatch Dashboard**: MÃ©tricas en tiempo real
- **Performance Monitoring**: Latencia y throughput
- **Cost Monitoring**: AnÃ¡lisis de costos por componente

---

## ğŸ” Troubleshooting

### Problemas Comunes

#### 1. **Error 502 - Bad Gateway**
```bash
# Verificar logs de Lambda
python simple_logs.py
```

#### 2. **Timeout en Lambda**
- Aumentar timeout en configuraciÃ³n
- Optimizar cÃ³digo de procesamiento
- Verificar tamaÃ±o de datos de entrada

#### 3. **Error de Permisos S3**
- Verificar IAM roles
- Comprobar polÃ­ticas de bucket
- Validar credenciales AWS

### Logs de Debug

```bash
# Logs del orquestador
python simple_logs.py

# Logs especÃ­ficos de GPU
python gpu_lambda_logs.py

# Logs especÃ­ficos de Spark
python spark_lambda_logs.py
```

---

## ğŸ“ Valor AcadÃ©mico

### Competencias Demostradas

#### **ProgramaciÃ³n Paralela**
- GPU processing con CUDA/OpenMP
- Multi-threading y vectorizaciÃ³n
- OptimizaciÃ³n de algoritmos paralelos

#### **ProgramaciÃ³n Distribuida**
- Actor model (Thespian/Akka)
- Microservicios y comunicaciÃ³n asÃ­ncrona
- CoordinaciÃ³n distribuida

#### **Big Data Processing**
- Apache Spark (RDD y DataFrame)
- AnÃ¡lisis de rendimiento y optimizaciÃ³n
- Escalabilidad horizontal

#### **Cloud Computing**
- AWS Lambda y serverless architecture
- Auto-scaling y elasticidad
- Cost optimization

#### **DevOps y CI/CD**
- Infrastructure as Code (Terraform)
- Automated deployment
- Monitoring y observabilidad

---

## ğŸ”® PrÃ³ximos Pasos

### Mejoras TÃ©cnicas

- **GPU Real**: Implementar CuPy con GPU fÃ­sica
- **EMR Real**: Usar cluster EMR en lugar de simulaciÃ³n
- **Streaming**: Implementar procesamiento en tiempo real
- **ML Integration**: AÃ±adir machine learning pipelines

### Escalabilidad

- **Horizontal Scaling**: Procesar datasets mÃ¡s grandes
- **Caching**: Implementar Redis para resultados frecuentes
- **Load Balancing**: Distribuir carga entre mÃºltiples instancias
- **Auto-scaling**: Configurar polÃ­ticas de escalado automÃ¡tico

### Monitoreo Avanzado

- **Custom Metrics**: MÃ©tricas especÃ­ficas del dominio
- **Alerting**: Alertas automÃ¡ticas para problemas
- **Performance Tuning**: OptimizaciÃ³n continua
- **Cost Optimization**: AnÃ¡lisis detallado de costos

---

## ğŸ“„ Licencia

Este proyecto es desarrollado para fines acadÃ©micos como parte de la asignatura "PROGRAMACIÃ“N PARALELA Y DISTRIBUIDA".

---

## ğŸ‘¥ Autores

- **Estudiante**: [Tu Nombre]
- **Asignatura**: ProgramaciÃ³n Paralela y Distribuida
- **Universidad**: [Tu Universidad]
- **Fecha**: Agosto 2025

---

## ğŸ“ Contacto

Para preguntas o soporte tÃ©cnico:
- **Email**: [tu-email@universidad.edu]
- **GitHub**: [tu-usuario-github]

---

*Proyecto desarrollado con â¤ï¸ para demostrar competencias avanzadas en programaciÃ³n paralela y distribuida.*
#   A c t i v i d a d _ I n t e g r a d o r a  
 